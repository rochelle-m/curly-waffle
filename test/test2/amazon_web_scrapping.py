# -*- coding: utf-8 -*-
"""amazon-web-scrapping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TEbn0KXwjXTFXzIzSL7jYQ8E9w6ipt7_
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
from urllib.request import urlopen
from bs4 import BeautifulSoup, Comment
import requests

no_pages = 2

def get_data(pageNo):  
    headers = {
        "User-Agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0", \
        "Accept-Encoding":"gzip, deflate", \
        "Accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8", \
        "DNT":"1", \
        "Connection":"close", \
        "Upgrade-Insecure-Requests":"1" \
    }

    r = requests.get('https://www.amazon.in/gp/bestsellers/pet-supplies/4771342031/ref=zg_bs_nav_pet-supplies_1_pet-supplies'+str(pageNo)+'?ie=UTF8&pg='+str(pageNo), headers=headers)
    content = r.content
    soup = BeautifulSoup(content)

    products = []
    for d in soup.findAll('div', attrs={'class':'a-section a-spacing-none aok-relative'}):
        product = []
        nameDiv = d.find('div', attrs={'class':'p13n-sc-truncate p13n-sc-line-clamp-2'})
        if nameDiv is not None:  
          name = nameDiv.text.strip()
          img = d.find('img', attrs={'alt':name})
          if img is not None:  
            product.append(name)
            src = img.get('src')
            product.append(src)
            
            price = d.find('span', attrs={'class':'p13n-sc-price'})
            product.append(price.text)
        products.append(product)
    return products

results = []
for i in range(1, no_pages+1):
    results.append(get_data(i))
flatten = lambda l: [item for sublist in l for item in sublist]
df = pd.DataFrame(flatten(results),columns=['Name','ImgSrc','Price'])
df = df.dropna()
df.to_csv('pet_products.csv', index=False, encoding='utf-8')

csv_file = pd.DataFrame(pd.read_csv("pet_products.csv", sep = ",", header = 0, index_col = False))

csv_file.to_json("pet_products.json", orient = "records", date_format = "epoch", double_precision = 10, force_ascii = True, date_unit = "ms", default_handler = None)